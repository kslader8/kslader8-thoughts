{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so I kind of live in Azure ML Workspace these days... leading me to want to make a small notebook utilizing it here. It's been changing pretty rapidly every ~6 months, so I'm going to include the versions I work on.\n",
    "\n",
    "If your company is going down the the Azure road for public cloud, Azure ML Workspace (or AWS SageMaker) is probably the best solution to scale easy access to compute, datasets, experiments, etc. to different data science teams accross a large organization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version 1.2.0\n",
      "numpy version 1.18.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(f\"pandas version {pd.__version__}\")\n",
    "print(f\"numpy version {np.__version__}\")\n",
    "# print(f\"tensorflow version {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml version 1.25.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core as aml\n",
    "\n",
    "from azureml.core import Workspace, ScriptRunConfig, Environment, Experiment, Run\n",
    "from azureml.core import Datastore, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "print(f\"azureml version {aml.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twelvedata version 1.1.7\n"
     ]
    }
   ],
   "source": [
    "import twelvedata\n",
    "from twelvedata import TDClient\n",
    "\n",
    "print(f\"twelvedata version {twelvedata.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = Path(\".env\")\n",
    "assert env_path.exists()\n",
    "_ = load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure ML Workspace\n",
    "To setup an Azure ML Workspace you will need an azure account (with credit card). To spin it up simply go to https://portal.azure.com/ and type machine learning in the search bar and create a workspace.\n",
    "\n",
    "Once you have a workspace you will need to download the config.json prior to going to https://ml.azure.com/ to access your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_config_path = Path(\"config.json\")\n",
    "assert workspace_config_path.exists()\n",
    "ws = Workspace.from_config(path=workspace_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twelve Data Client\n",
    "I setup an account at https://twelvedata.com/ to get a free api key to try it out. I had not heard of it before, but it was the first thing that came up in my google search for free market data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.environ.get(\"apikey\")\n",
    "td = TDClient(apikey=apikey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Workspace Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating...\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-03-31T18:41:03.129000+00:00', 'errors': None, 'creationTime': '2021-03-31T18:41:00.552530+00:00', 'modifiedTime': '2021-03-31T18:41:16.029047+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "compute_name = \"aml-compute\"\n",
    "vm_size = \"Standard_NC6\"\n",
    "# vm_size = \"Standard_NC6s_v3\"\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found compute target: ' + compute_name)\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,  # STANDARD_NC6 is GPU-enabled\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=4)\n",
    "    # create the compute target\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current cluster status, use the 'status' property\n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Workspace Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TwelveData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List ETFs Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>currency</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8PSG</td>\n",
       "      <td>Invesco Physical Gold ETC</td>\n",
       "      <td>EUR</td>\n",
       "      <td>XETR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>BetaShares Australian High Interest Cash ETF</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ASX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>USD</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AADR</td>\n",
       "      <td>AdvisorShares Dorsey Wright ADR ETF</td>\n",
       "      <td>USD</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AASF</td>\n",
       "      <td>Airlie Australian Share Fund -- ETF Feeder</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ASX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                                          name currency exchange\n",
       "0   8PSG                     Invesco Physical Gold ETC      EUR     XETR\n",
       "1    AAA  BetaShares Australian High Interest Cash ETF      AUD      ASX\n",
       "2   AAAU                  Perth Mint Physical Gold ETF      USD     NYSE\n",
       "3   AADR           AdvisorShares Dorsey Wright ADR ETF      USD     NYSE\n",
       "4   AASF    Airlie Australian Share Fund -- ETF Feeder      AUD      ASX"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etf_data = td.get_etf_list()\n",
    "etf_list = etf_data.as_json()\n",
    "etf_df = pd.DataFrame(etf_list)\n",
    "etf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ETF Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2020, 4, 13), datetime.date(2021, 3, 31))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_date = pd.Timestamp(dt.datetime.today())\n",
    "start_date = end_date - pd.tseries.offsets.BDay(252)\n",
    "\n",
    "start_date.to_pydatetime().date(), end_date.to_pydatetime().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>2.410000e+02</td>\n",
       "      <td>241.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>315.827105</td>\n",
       "      <td>318.008939</td>\n",
       "      <td>313.696467</td>\n",
       "      <td>316.061946</td>\n",
       "      <td>3.388346e+06</td>\n",
       "      <td>314.099308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.935291</td>\n",
       "      <td>30.777465</td>\n",
       "      <td>31.051232</td>\n",
       "      <td>30.962168</td>\n",
       "      <td>1.384690e+06</td>\n",
       "      <td>31.300765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>250.960010</td>\n",
       "      <td>255.490010</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.960010</td>\n",
       "      <td>7.530980e+05</td>\n",
       "      <td>247.567540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>294.420010</td>\n",
       "      <td>296.386990</td>\n",
       "      <td>293.149990</td>\n",
       "      <td>294.780000</td>\n",
       "      <td>2.359274e+06</td>\n",
       "      <td>289.318520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>314.355010</td>\n",
       "      <td>316.260010</td>\n",
       "      <td>312.989990</td>\n",
       "      <td>314.810000</td>\n",
       "      <td>3.065109e+06</td>\n",
       "      <td>313.609280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>342.239990</td>\n",
       "      <td>344.370000</td>\n",
       "      <td>340.179990</td>\n",
       "      <td>341.989990</td>\n",
       "      <td>4.069956e+06</td>\n",
       "      <td>340.674540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>365.079990</td>\n",
       "      <td>366.049990</td>\n",
       "      <td>363.250000</td>\n",
       "      <td>365.410000</td>\n",
       "      <td>8.397805e+06</td>\n",
       "      <td>362.513420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open        high         low       close        volume  \\\n",
       "count  241.000000  241.000000  241.000000  241.000000  2.410000e+02   \n",
       "mean   315.827105  318.008939  313.696467  316.061946  3.388346e+06   \n",
       "std     30.935291   30.777465   31.051232   30.962168  1.384690e+06   \n",
       "min    250.960010  255.490010  250.000000  250.960010  7.530980e+05   \n",
       "25%    294.420010  296.386990  293.149990  294.780000  2.359274e+06   \n",
       "50%    314.355010  316.260010  312.989990  314.810000  3.065109e+06   \n",
       "75%    342.239990  344.370000  340.179990  341.989990  4.069956e+06   \n",
       "max    365.079990  366.049990  363.250000  365.410000  8.397805e+06   \n",
       "\n",
       "              ema  \n",
       "count  241.000000  \n",
       "mean   314.099308  \n",
       "std     31.300765  \n",
       "min    247.567540  \n",
       "25%    289.318520  \n",
       "50%    313.609280  \n",
       "75%    340.674540  \n",
       "max    362.513420  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"VOO\"\n",
    "ts = td.time_series(\n",
    "    symbol=ticker, \n",
    "    interval=\"1day\",\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    outputsize=300\n",
    ")\n",
    "\n",
    "df = ts.with_ema().as_pandas()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>362.85999</td>\n",
       "      <td>365.82001</td>\n",
       "      <td>362.85999</td>\n",
       "      <td>365.41000</td>\n",
       "      <td>2687756</td>\n",
       "      <td>362.51342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>363.79001</td>\n",
       "      <td>363.79001</td>\n",
       "      <td>361.28500</td>\n",
       "      <td>363.00000</td>\n",
       "      <td>3637520</td>\n",
       "      <td>361.78927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>362.66000</td>\n",
       "      <td>364.67001</td>\n",
       "      <td>361.10971</td>\n",
       "      <td>363.79001</td>\n",
       "      <td>3062900</td>\n",
       "      <td>361.48659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>359.42999</td>\n",
       "      <td>364.35001</td>\n",
       "      <td>358.75000</td>\n",
       "      <td>363.95999</td>\n",
       "      <td>3212525</td>\n",
       "      <td>360.91074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>357.42001</td>\n",
       "      <td>360.23999</td>\n",
       "      <td>354.14001</td>\n",
       "      <td>359.47000</td>\n",
       "      <td>5361270</td>\n",
       "      <td>360.14842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime       open       high        low      close   volume        ema\n",
       "0 2021-03-31  362.85999  365.82001  362.85999  365.41000  2687756  362.51342\n",
       "1 2021-03-30  363.79001  363.79001  361.28500  363.00000  3637520  361.78927\n",
       "2 2021-03-29  362.66000  364.67001  361.10971  363.79001  3062900  361.48659\n",
       "3 2021-03-26  359.42999  364.35001  358.75000  363.95999  3212525  360.91074\n",
       "4 2021-03-25  357.42001  360.23999  354.14001  359.47000  5361270  360.14842"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure Workspace Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload ETF Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-26 04:00:00</td>\n",
       "      <td>359.42999</td>\n",
       "      <td>364.35001</td>\n",
       "      <td>358.75000</td>\n",
       "      <td>363.95999</td>\n",
       "      <td>3212525</td>\n",
       "      <td>360.91074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-25 04:00:00</td>\n",
       "      <td>357.42001</td>\n",
       "      <td>360.23999</td>\n",
       "      <td>354.14001</td>\n",
       "      <td>359.47000</td>\n",
       "      <td>5361270</td>\n",
       "      <td>360.14842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-24 04:00:00</td>\n",
       "      <td>360.70999</td>\n",
       "      <td>362.26999</td>\n",
       "      <td>357.44000</td>\n",
       "      <td>357.57999</td>\n",
       "      <td>3989728</td>\n",
       "      <td>360.31803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-23 04:00:00</td>\n",
       "      <td>359.79501</td>\n",
       "      <td>362.51001</td>\n",
       "      <td>359.79501</td>\n",
       "      <td>362.32001</td>\n",
       "      <td>1208455</td>\n",
       "      <td>361.00254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-22 04:00:00</td>\n",
       "      <td>359.88000</td>\n",
       "      <td>363.50000</td>\n",
       "      <td>359.76999</td>\n",
       "      <td>362.10999</td>\n",
       "      <td>3320390</td>\n",
       "      <td>360.67317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime       open       high        low      close   volume  \\\n",
       "0 2021-03-26 04:00:00  359.42999  364.35001  358.75000  363.95999  3212525   \n",
       "1 2021-03-25 04:00:00  357.42001  360.23999  354.14001  359.47000  5361270   \n",
       "2 2021-03-24 04:00:00  360.70999  362.26999  357.44000  357.57999  3989728   \n",
       "3 2021-03-23 04:00:00  359.79501  362.51001  359.79501  362.32001  1208455   \n",
       "4 2021-03-22 04:00:00  359.88000  363.50000  359.76999  362.10999  3320390   \n",
       "\n",
       "         ema  \n",
       "0  360.91074  \n",
       "1  360.14842  \n",
       "2  360.31803  \n",
       "3  361.00254  \n",
       "4  360.67317  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_or_upload_df(ws, data_store, df, ticker):\n",
    "    \n",
    "    dataset_name = f'{ticker.lower()}_ds'\n",
    "    try: \n",
    "        ds = Dataset.get_by_name(workspace=ws, name=dataset_name)\n",
    "        df = ds.to_pandas_dataframe()\n",
    "    except:\n",
    "        Dataset.Tabular.register_pandas_dataframe(df, data_store, dataset_name)\n",
    "        ds = Dataset.get_by_name(workspace=ws, name=dataset_name)\n",
    "        df = ds.to_pandas_dataframe()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "aml_df = get_or_upload_df(ws, data_store, df.reset_index(), ticker)\n",
    "aml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'aml-exp'\n",
    "aml_exp = Path(src_dir)\n",
    "if not aml_exp.exists(): aml_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aml-exp/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile aml-exp/train.py\n",
    "\n",
    "# Standard Libraries\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "# 3rd Party Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Model\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Classes \n",
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df,\n",
    "               label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "            # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "            # And cache it for next time\n",
    "            self._example = result\n",
    "        return result\n",
    "    \n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    def plot(self, plot_col, model=None, max_subplots=3):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        \n",
    "        # TODO - plot function\n",
    "        \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "          data=data,\n",
    "          targets=None,\n",
    "          sequence_length=self.total_window_size,\n",
    "          sequence_stride=1,\n",
    "          shuffle=True,\n",
    "          batch_size=32,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]\n",
    "    \n",
    "# Global Variables\n",
    "MAX_EPOCHS = 20\n",
    "CONV_WIDTH = 3\n",
    "\n",
    "# Read in Args\n",
    "parser = argparse.ArgumentParser(description='Train')\n",
    "parser.add_argument('--dataset_name', type=str, dest='dataset_name')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Paths\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "os.makedirs('./outputs/model', exist_ok=True)\n",
    "\n",
    "\n",
    "# ML Run\n",
    "run = Run.get_context()\n",
    "workspace = run.experiment.workspace\n",
    "\n",
    "\n",
    "# ML Dataset\n",
    "ds = Dataset.get_by_name(workspace=workspace, name=args.dataset_name)\n",
    "df = ds.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "# Date Feature Prep\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "date_time = pd.to_datetime(df.datetime)\n",
    "timestamp_s = date_time.map(dt.datetime.timestamp)\n",
    "\n",
    "df['day_sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['day_cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['year_sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['year_cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "\n",
    "\n",
    "# Data Filter\n",
    "features = ['day_sin', 'day_cos', 'ema']\n",
    "target = 'close'\n",
    "columns = features + [target]\n",
    "df = df[columns]\n",
    "\n",
    "# Data Splitting\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "\n",
    "# Data Normalization\n",
    "# TODO - normalize step based on train_df\n",
    "\n",
    "# Data Windows\n",
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=[target])\n",
    "wide_window = WindowGenerator(\n",
    "    input_width=24, label_width=24, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=[target])\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=[target])\n",
    "\n",
    "\n",
    "# Train Baseline\n",
    "baseline = Baseline(label_index=single_step_window.column_indices.get(target))\n",
    "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance, tst_performance = {}, {}\n",
    "val_performance['baseline'] = baseline.evaluate(single_step_window.val)\n",
    "tst_performance['baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\n",
    "\n",
    "# Train Models\n",
    "def compile_and_fit(model, window, patience=4):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "    return history\n",
    "\n",
    "# Train Linear Model\n",
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "history = compile_and_fit(linear, single_step_window)\n",
    "\n",
    "val_performance['linear'] = linear.evaluate(single_step_window.val)\n",
    "tst_performance['linear'] = linear.evaluate(single_step_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(linear, './outputs/model/linear')\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax = fig1.add_subplot(111)\n",
    "ax.bar(x = range(len(train_df.columns)),\n",
    "        height=linear.layers[0].kernel[:,0].numpy())\n",
    "ax.set_xticks(range(len(train_df.columns)))\n",
    "_ = ax.set_xticklabels(train_df.columns, rotation=90)\n",
    "run.log_image('linear_coef', plot=plt)\n",
    "\n",
    "# Train Single Step Dense Model\n",
    "single_step_dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "history = compile_and_fit(single_step_dense, single_step_window)\n",
    "\n",
    "val_performance['single_step_dense'] = single_step_dense.evaluate(single_step_window.val)\n",
    "tst_performance['single_step_dense'] = single_step_dense.evaluate(single_step_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(single_step_dense, './outputs/model/single_step_dense')\n",
    "\n",
    "# Train Multi Step Dense Model\n",
    "multi_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])\n",
    "history = compile_and_fit(multi_step_dense, conv_window)\n",
    "\n",
    "val_performance['multi_step_dense'] = multi_step_dense.evaluate(conv_window.val)\n",
    "tst_performance['multi_step_dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(multi_step_dense, './outputs/model/multi_step_dense')\n",
    "\n",
    "# Train Conv Model\n",
    "conv = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])\n",
    "history = compile_and_fit(conv, conv_window)\n",
    "\n",
    "val_performance['conv'] = conv.evaluate(conv_window.val)\n",
    "tst_performance['conv'] = conv.evaluate(conv_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(conv, './outputs/model/conv')\n",
    "\n",
    "# Train LSTM Model\n",
    "lstm = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(10, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "history = compile_and_fit(lstm, wide_window)\n",
    "\n",
    "val_performance['lstm'] = lstm.evaluate(wide_window.val)\n",
    "tst_performance['lstm'] = lstm.evaluate(wide_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(lstm, './outputs/model/lstm')\n",
    "\n",
    "# Performance\n",
    "x = np.arange(len(val_performance))\n",
    "width = 0.3\n",
    "\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = lstm.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in tst_performance.values()]\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(111)\n",
    "b1 = ax.bar(x - 0.2, val_mae, width, label='validation')\n",
    "# b2 = ax.bar(x + 0.2, test_mae, width, label='test')\n",
    "ax.set_xticks(range(len(val_mae)))\n",
    "_ = ax.set_xticklabels(val_performance.keys(), rotation=90)\n",
    "run.log_image('performance_mae', plot=plt)\n",
    "\n",
    "\n",
    "# Log Results & Select Best Model\n",
    "best_model, best_score = None, None\n",
    "if run is not None:\n",
    "    \n",
    "    for k, v in val_performance.items():\n",
    "        run.log_list(f'val_{k}', v)\n",
    "        \n",
    "    for k, v in tst_performance.items():\n",
    "        run.log_list(f'tst_{k}', v)\n",
    "        try:\n",
    "            mae = float(v[1])    \n",
    "            if best_score is None and best_model is None: \n",
    "                best_model = k\n",
    "                best_score = mae\n",
    "            elif best_score > mae:\n",
    "                best_model = k\n",
    "                best_score = mae   \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    run.log('best_model', best_model)\n",
    "    run.log('best_score', best_score)\n",
    "\n",
    "if best_model != \"baseline\": model = run.register_model(model_name=best_model, model_path=f'outputs/model/{best_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Training Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_run_config = RunConfiguration()\n",
    "aml_run_config.target = compute_target\n",
    "\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Add some packages relied on by data prep step\n",
    "deps = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn', 'matplotlib'], \n",
    "    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]', 'azureml-pipeline', 'azureml-interpret'], \n",
    "    python_version='3.6.2',\n",
    "    pin_sdk_version=True)\n",
    "deps.add_tensorflow_pip_package(core_type='gpu', version='2.3.1')\n",
    "aml_run_config.environment.python.conda_dependencies = deps\n",
    "\n",
    "\n",
    "src = ScriptRunConfig(source_directory=src_dir,\n",
    "                      script='train.py',\n",
    "                      arguments=['--dataset_name', f'{ticker.lower()}_ds'],\n",
    "                      run_config=aml_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "experiment = Experiment(ws, 'aml_exp')\n",
    "script_run = experiment.submit(src)\n",
    "script_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aca0a43d6774b6a87ccc0d5301494ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/aml_exp_1617218351_68997fbe?wsid=/subscriptions/f3b5840b-706e-44ba-8aa1-6fd3fc8aaab0/resourcegroups/ds-workspace/workspaces/minion-lab&tid=e6777dcd-6f87-4dd0-92e5-e98312157dac\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"run_properties\": {\"run_id\": \"aml_exp_1617218351_68997fbe\", \"created_utc\": \"2021-03-31T19:19:13.966579Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"fd92509f-ed37-4346-baf6-1818916e0050\", \"azureml.git.repository_uri\": \"https://github.com/kslader8/kslader8-thoughts.git\", \"mlflow.source.git.repoURL\": \"https://github.com/kslader8/kslader8-thoughts.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"720edf92d0336f47ef43c050cbd8ac64a866f5c9\", \"mlflow.source.git.commit\": \"720edf92d0336f47ef43c050cbd8ac64a866f5c9\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-03-31T19:25:41.92001Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/azureml-logs/55_azureml-execution-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt?sv=2019-02-02&sr=b&sig=F3JM%2FgLzL3AnpdPGox2mP1%2B8xzmTn%2BSotpMMD%2Bwk83Y%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/azureml-logs/65_job_prep-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt?sv=2019-02-02&sr=b&sig=KQcJDSYAfYmJDxoGd6WGdhUmhv4Q%2BcwVGPjv%2FC0Bky0%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=XLbdBEXiQbgocSzc2EGGcBvhi04syLJAiP%2FhrK6SEtA%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"azureml-logs/75_job_post-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/azureml-logs/75_job_post-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt?sv=2019-02-02&sr=b&sig=cCSJwWyywwIdDhocXQcmvhoDCLNpJUbgcrTmPXd2fMs%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"azureml-logs/process_info.json\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Bs%2B3obHWkZi%2BUUgBCWt378R2IhJgG9FByLCYNOkZFIk%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"azureml-logs/process_status.json\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=BPTxOX%2FGab2jYxsNr7W1vP9NTcyy4u7Qz473KVAntIA%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"logs/azureml/106_azureml.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/logs/azureml/106_azureml.log?sv=2019-02-02&sr=b&sig=5oFYwwgTfiFW3igHc0Jiw2cGsUwovLQHQpXiPoDYXLQ%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=zcdJcvnUqrSivrRP1cW0lq7ixucJoewgiAamLVBDxx8%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=2hLP3Ho0cdqXjdH8DL%2BQjmVAm3smjiUE5HBmBzYtnso%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=pRVesqxbDs9czgCzJp8CHO9mXSBN5YRedn6DPOXqZ98%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=beiFVCcsatMyS4RGbXcBV2QCswt%2BaRORdxJP55WV9YQ%3D&st=2021-03-31T19%3A16%3A08Z&se=2021-04-01T03%3A26%3A08Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt\"], [\"logs/azureml/106_azureml.log\"]], \"run_duration\": \"0:06:27\", \"run_number\": \"19\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"linear_coef\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/linear_coef_1617218696.png\"]}]}, {\"name\": \"performance_mae\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/performance_mae_1617218715.png\"]}]}, {\"name\": \"val_baseline\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [18.686260223388672, 3.2065956592559814]}]}, {\"name\": \"val_linear\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [25045.705078125, 158.12350463867188]}]}, {\"name\": \"val_single_step_dense\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [12.049277305603027, 2.5712552070617676]}]}, {\"name\": \"val_multi_step_dense\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [105.29651641845703, 9.513522148132324]}]}, {\"name\": \"val_conv\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [16.507810592651367, 2.9061272144317627]}]}, {\"name\": \"val_lstm\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [80574.6171875, 283.7806091308594]}]}, {\"name\": \"tst_baseline\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [20.958070755004883, 3.920870542526245]}]}, {\"name\": \"tst_linear\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [20818.353515625, 144.19789123535156]}]}, {\"name\": \"tst_single_step_dense\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [14.024746894836426, 3.2437658309936523]}]}, {\"name\": \"tst_multi_step_dense\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [70.03379821777344, 7.117403507232666]}]}, {\"name\": \"tst_conv\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0, 1], \"series\": [{\"data\": [20.42483901977539, 3.2997443675994873]}]}, {\"name\": \"best_model\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0], \"series\": [{\"data\": [\"single_step_dense\"]}]}, {\"name\": \"best_score\", \"run_id\": \"aml_exp_1617218351_68997fbe\", \"categories\": [0], \"series\": [{\"data\": [3.2437658309936523]}]}], \"run_logs\": \"2021-03-31 19:24:40,272|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-03-31 19:24:40,272|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-03-31 19:24:40,294|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-03-31 19:24:40,294|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-03-31 19:24:40,696|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2021-03-31 19:24:40,697|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2021-03-31 19:24:40,697|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2021-03-31 19:24:40,697|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2021-03-31 19:24:40,697|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7fa88c0e27b8> for run source hyperdrive\\n2021-03-31 19:24:40,716|azureml.core|WARNING|Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-dataprep 2.13.2 (/azureml-envs/azureml_7c53d162ce55be5bb112991a6f053fb8/lib/python3.6/site-packages), Requirement.parse('azureml-dataprep<2.12.0a,>=2.11.0a'), {'azureml-dataset-runtime'}).\\n2021-03-31 19:24:40,762|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7fa88bf57f28> for run source azureml.PipelineRun\\n2021-03-31 19:24:40,771|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7fa88bf619d8> for run source azureml.ReusedStepRun\\n2021-03-31 19:24:40,780|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7fa88bf61950> for run source azureml.StepRun\\n2021-03-31 19:24:40,789|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fa88c2641e0> for run source azureml.scriptrun\\n2021-03-31 19:24:40,790|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 19:24:40,790|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 19:24:40,792|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 19:24:40,800|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-03-31 19:24:40,800|azureml.core.authentication|DEBUG|Time to expire 1814072.199729 seconds\\n2021-03-31 19:24:40,800|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-03-31 19:24:40,800|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-03-31 19:24:41,076|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:41,077|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:41,077|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:41,077|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:41,077|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:41,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:41,078|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:41,114|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 19:24:41,114|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 19:24:41,189|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 19:24:41,190|azureml._SubmittedRun#aml_exp_1617218351_68997fbe|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'fd92509f-ed37-4346-baf6-1818916e0050', 'azureml.git.repository_uri': 'https://github.com/kslader8/kslader8-thoughts.git', 'mlflow.source.git.repoURL': 'https://github.com/kslader8/kslader8-thoughts.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '720edf92d0336f47ef43c050cbd8ac64a866f5c9', 'mlflow.source.git.commit': '720edf92d0336f47ef43c050cbd8ac64a866f5c9', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-31 19:24:41,190|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-31 19:24:41,191|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-03-31 19:24:41,191|azureml.WorkerPool|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml.RunStatusContext|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml.MetricsClient|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-03-31 19:24:41,191|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617218351_68997fbe/mounts/workspaceblobstore/azureml/aml_exp_1617218351_68997fbe\\n2021-03-31 19:24:41,192|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-31 19:24:41,192|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617218351_68997fbe/mounts/workspaceblobstore/azureml/aml_exp_1617218351_68997fbe\\n2021-03-31 19:24:43,818|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 19:24:43,818|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 19:24:43,819|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 19:24:43,820|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:43,821|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:43,822|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:43,823|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:43,829|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:43,829|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:43,829|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:43,867|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 19:24:43,867|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 19:24:43,927|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 19:24:43,929|azureml._SubmittedRun#aml_exp_1617218351_68997fbe|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'fd92509f-ed37-4346-baf6-1818916e0050', 'azureml.git.repository_uri': 'https://github.com/kslader8/kslader8-thoughts.git', 'mlflow.source.git.repoURL': 'https://github.com/kslader8/kslader8-thoughts.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '720edf92d0336f47ef43c050cbd8ac64a866f5c9', 'mlflow.source.git.commit': '720edf92d0336f47ef43c050cbd8ac64a866f5c9', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-31 19:24:43,929|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-31 19:24:44,138|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 19:24:44,139|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 19:24:44,139|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 19:24:44,140|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,142|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,144|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,144|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,145|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,145|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,145|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,745|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 19:24:44,745|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 19:24:44,746|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 19:24:44,746|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,746|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,747|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,747|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,747|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,747|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:44,747|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,407|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 19:24:50,407|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 19:24:50,408|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 19:24:50,408|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,409|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,409|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,409|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,410|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,410|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,410|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 19:24:50,418|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 19:24:50,418|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 19:24:50,552|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 19:24:56,406|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-03-31 19:24:56,407|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-03-31 19:24:56,407|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-31 19:24:56,407|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-31 19:24:56,565|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-31 19:24:56,565|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-31 19:24:56,640|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.aml_exp_1617218351_68997fbe/linear_coef_1617218696.png with size 10712, file size 10712.\\n2021-03-31 19:24:56,640|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 19:24:56,640|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 19:24:56,641|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 19:24:57,641|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-31 19:24:57,641|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-31 19:24:57,641|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-03-31 19:24:57,642|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-31 19:24:57,642|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-31 19:24:57,642|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-31 19:24:57,642|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-03-31 19:24:57,642|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-31 19:24:57,642|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-31 19:24:57,642|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-31 19:24:57,643|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-31 19:24:57,643|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-03-31 19:24:57,643|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-31 19:24:57,643|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-31 19:24:57,648|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-31 19:24:57,648|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-31 19:24:57,648|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-31 19:24:57,648|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-31 19:24:57,649|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-03-31 19:24:57,649|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-31 19:24:57,801|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:10,793|azureml.core.authentication|DEBUG|Time to expire 1814042.206803 seconds\\n2021-03-31 19:25:15,136|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-03-31 19:25:15,136|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-03-31 19:25:15,136|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-31 19:25:15,136|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-31 19:25:15,305|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:15,305|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-31 19:25:15,336|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.aml_exp_1617218351_68997fbe/performance_mae_1617218715.png with size 11589, file size 11589.\\n2021-03-31 19:25:15,338|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.aml_exp_1617218351_68997fbe, outputs/model/single_step_dense\\n2021-03-31 19:25:15,338|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2021-03-31 19:25:15,338|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2021-03-31 19:25:15,339|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2021-03-31 19:25:15,342|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2021-03-31 19:25:15,342|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2021-03-31 19:25:15,342|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2021-03-31 19:25:15,342|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2021-03-31 19:25:15,436|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2021-03-31 19:25:15,437|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2021-03-31 19:25:15,437|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[START]\\n2021-03-31 19:25:15,437|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.AssetsClient|DEBUG|ClientBase: Calling create with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/assets\\n2021-03-31 19:25:15,559|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:15,565|azureml.ModelsClient.register-async:False|DEBUG|[START]\\n2021-03-31 19:25:15,566|azureml.ModelsClient|DEBUG|ClientBase: Calling register with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models\\n2021-03-31 19:25:15,654|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-31 19:25:15,654|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-31 19:25:15,654|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 15.\\n2021-03-31 19:25:15,655|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-31 19:25:15,655|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-31 19:25:15,655|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-31 19:25:15,655|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 15 values.\\n2021-03-31 19:25:15,655|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-31 19:25:15,655|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-31 19:25:15,655|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-31 19:25:15,656|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 1__log_batch_v2 to queue of approximate size: 1\\n2021-03-31 19:25:15,656|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-31 19:25:15,656|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-31 19:25:15,656|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-31 19:25:15,664|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-31 19:25:15,664|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-31 19:25:15,664|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-31 19:25:15,664|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-31 19:25:15,664|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-03-31 19:25:15,664|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-31 19:25:15,892|azureml.ModelsClient.register-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:15,893|azureml.WorkspaceClient.get-async:False|DEBUG|[START]\\n2021-03-31 19:25:15,894|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}\\n2021-03-31 19:25:15,982|azureml.WorkspaceClient.get-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:15,982|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 19:25:15,982|azureml.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 19:25:16,574|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|WARNING|Metrics Client: Failed to post metric with name tst_lstm due to the following error \\\"Metric column found with a malformed type\\nMetric column found with a malformed type\\\"\\n2021-03-31 19:25:16,574|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:16,739|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:16,740|azureml.core.run|DEBUG|Available factories for run types {'hyperdrive': <function HyperDriveRun._from_run_dto at 0x7fa88c0e27b8>, 'azureml.PipelineRun': <function PipelineRun._from_dto at 0x7fa88bf57f28>, 'azureml.ReusedStepRun': <function StepRun._from_reused_dto at 0x7fa88bf619d8>, 'azureml.StepRun': <function StepRun._from_dto at 0x7fa88bf61950>, 'azureml.scriptrun': <function ScriptRun._from_run_dto at 0x7fa88c2641e0>}\\n2021-03-31 19:25:16,740|azureml.core.run|DEBUG|Initializing Run aml_exp_1617218351_68997fbe from type azureml.scriptrun\\n2021-03-31 19:25:16,743|azureml.ScriptRun#aml_exp_1617218351_68997fbe|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'fd92509f-ed37-4346-baf6-1818916e0050', 'azureml.git.repository_uri': 'https://github.com/kslader8/kslader8-thoughts.git', 'mlflow.source.git.repoURL': 'https://github.com/kslader8/kslader8-thoughts.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '720edf92d0336f47ef43c050cbd8ac64a866f5c9', 'mlflow.source.git.commit': '720edf92d0336f47ef43c050cbd8ac64a866f5c9', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-31 19:25:16,743|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-31 19:25:16,818|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-31 19:25:16,818|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617218351_68997fbe/mounts/workspaceblobstore/azureml/aml_exp_1617218351_68997fbe\\n2021-03-31 19:25:16,819|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617218351_68997fbe/mounts/workspaceblobstore/azureml/aml_exp_1617218351_68997fbe to /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617218351_68997fbe/mounts/workspaceblobstore/azureml/aml_exp_1617218351_68997fbe\\n2021-03-31 19:25:16,819|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617218351_68997fbe/mounts/workspaceblobstore/azureml/aml_exp_1617218351_68997fbe\\n2021-03-31 19:25:16,819|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-03-31 19:25:16,819|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-03-31 19:25:16,819|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 19:25:16,819|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 19:25:16,819|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 19:25:16,819|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:16,820|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-03-31 19:25:16,821|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 19:25:16,821|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:16,821|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:16,821|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 19:25:16,821|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 19:25:17,971|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:17,972|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:17,972|azureml.MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:17,972|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 19:25:17,972|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 19:25:17,973|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 19:25:18,138|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:18,139|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-03-31 19:25:18,139|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 19:25:18,139|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:18,139|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:18,139|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 19:25:18,139|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 19:25:18,139|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 19:25:18,140|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 19:25:19,280|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:19,280|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 19:25:19,280|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 19:25:19,280|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2), AsyncTask(1__log_batch_v2)].\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-31 19:25:19,281|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 19:25:19,282|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 19:25:19,371|azureml._SubmittedRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:19,372|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 19:25:19,372|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 19:25:19,372|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 19:25:19,372|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 19:25:19,372|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:19,372|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:19,372|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 19:25:19,373|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:19,374|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 19:25:19,374|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 19:25:19,374|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 19:25:19,438|azureml.ScriptRun#aml_exp_1617218351_68997fbe.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 19:25:19,439|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-03-31 19:25:19,439|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-03-31 19:25:19,439|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-03-31 19:25:19,439|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.25.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(script_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it best to simply go to the experiment portal url to review from the gui. It contains all the runs from your experiment and makes it easy to review changes from a central location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/aml_exp_1617218351_68997fbe?wsid=/subscriptions/f3b5840b-706e-44ba-8aa1-6fd3fc8aaab0/resourcegroups/ds-workspace/workspaces/minion-lab&tid=e6777dcd-6f87-4dd0-92e5-e98312157dac'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_run.get_portal_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can choose to do the model review inside the notebook too. \n",
    "\n",
    "The first place to look when doing this is the experiments metrics. In this example I'm logging the mse and mae for validation & test datasets for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_coef': 'aml://artifactId/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/linear_coef_1617218696.png',\n",
       " 'performance_mae': 'aml://artifactId/ExperimentRun/dcid.aml_exp_1617218351_68997fbe/performance_mae_1617218715.png',\n",
       " 'val_baseline': [18.686260223388672, 3.2065956592559814],\n",
       " 'val_linear': [25045.705078125, 158.12350463867188],\n",
       " 'val_single_step_dense': [12.049277305603027, 2.5712552070617676],\n",
       " 'val_multi_step_dense': [105.29651641845703, 9.513522148132324],\n",
       " 'val_conv': [16.507810592651367, 2.9061272144317627],\n",
       " 'val_lstm': [80574.6171875, 283.7806091308594],\n",
       " 'tst_baseline': [20.958070755004883, 3.920870542526245],\n",
       " 'tst_linear': [20818.353515625, 144.19789123535156],\n",
       " 'tst_single_step_dense': [14.024746894836426, 3.2437658309936523],\n",
       " 'tst_multi_step_dense': [70.03379821777344, 7.117403507232666],\n",
       " 'tst_conv': [20.42483901977539, 3.2997443675994873],\n",
       " 'best_model': 'single_step_dense',\n",
       " 'best_score': 3.2437658309936523}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = script_run.get_metrics()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_val             : 3.2066\n",
      "baseline_tst             : 3.9209\n",
      "conv_val                 : 2.9061\n",
      "conv_tst                 : 3.2997\n",
      "linear_val               : 158.1235\n",
      "linear_tst               : 144.1979\n",
      "lstm_val                 : 283.7806\n",
      "multi_step_dense_val     : 9.5135\n",
      "multi_step_dense_tst     : 7.1174\n",
      "single_step_dense_val    : 2.5713\n",
      "single_step_dense_tst    : 3.2438\n"
     ]
    }
   ],
   "source": [
    "mae_metrics = []\n",
    "for name, value in metrics.items():\n",
    "    if isinstance(value, list) and len(value) >= 2:\n",
    "        splits = name.split(\"_\")\n",
    "        grp, model = splits[0], \"_\".join(splits[1:])\n",
    "        mae_metrics.append((model, grp, value[1]))\n",
    "        \n",
    "for model, grp, mae in sorted(mae_metrics, key=lambda o: o[0]):\n",
    "    name = f'{model}_{grp}'\n",
    "    print(f'{name:25s}: {mae:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be useful to review the log files to figure out wtf is going wrong constantly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/55_azureml-execution-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt',\n",
       " 'azureml-logs/70_driver_log.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_0131a389317277292ba2a81189e3531d414e8ac8f29d13fd64056daa66d1597f_d.txt',\n",
       " 'azureml-logs/process_info.json',\n",
       " 'azureml-logs/process_status.json',\n",
       " 'linear_coef_1617218696.png',\n",
       " 'logs/azureml/106_azureml.log',\n",
       " 'logs/azureml/dataprep/backgroundProcess.log',\n",
       " 'logs/azureml/dataprep/backgroundProcess_Telemetry.log',\n",
       " 'logs/azureml/job_prep_azureml.log',\n",
       " 'logs/azureml/job_release_azureml.log',\n",
       " 'outputs/model/conv/saved_model.pb',\n",
       " 'outputs/model/conv/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/conv/variables/variables.index',\n",
       " 'outputs/model/linear/saved_model.pb',\n",
       " 'outputs/model/linear/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/linear/variables/variables.index',\n",
       " 'outputs/model/lstm/saved_model.pb',\n",
       " 'outputs/model/lstm/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/lstm/variables/variables.index',\n",
       " 'outputs/model/multi_step_dense/saved_model.pb',\n",
       " 'outputs/model/multi_step_dense/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/multi_step_dense/variables/variables.index',\n",
       " 'outputs/model/single_step_dense/saved_model.pb',\n",
       " 'outputs/model/single_step_dense/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/single_step_dense/variables/variables.index',\n",
       " 'performance_mae_1617218715.png']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = script_run.get_file_names()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "# from azureml.tensorboard import Tensorboard\n",
    "\n",
    "# tb = Tensorboard([run])\n",
    "# tb.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "This is an important step if you don't want to end up having a big bill at the end of the month 😉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting compute cleanup\n",
      "deleting aml-compute instance\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "compute cleanup complete\n"
     ]
    }
   ],
   "source": [
    "print(\"starting compute cleanup\")\n",
    "\n",
    "for name, compute in ws.compute_targets.items():\n",
    "    print(f\"deleting {name} instance\")\n",
    "    compute.delete()\n",
    "    \n",
    "while len(ws.compute_targets.items()) != 0:\n",
    "    continue\n",
    "\n",
    "print(\"compute cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
