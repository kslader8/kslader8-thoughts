{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Workspace - [Tensorflow] Time Series Example\n",
    "categories: [azureml, tensorflow, time-series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so I kind of live in Azure ML Workspace these days... leading me to want to make a small notebook utilizing it here. It's been changing pretty rapidly every ~6 months, so I'm going to include the versions I work on.\n",
    "\n",
    "If your company is going down the the Azure road for public cloud, Azure ML Workspace (or AWS SageMaker) is probably the best solution to scale easy access to compute, datasets, experiments, etc. to different data science teams accross a large organization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version 1.2.0\n",
      "numpy version 1.18.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(f\"pandas version {pd.__version__}\")\n",
    "print(f\"numpy version {np.__version__}\")\n",
    "# print(f\"tensorflow version {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml version 1.25.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core as aml\n",
    "\n",
    "from azureml.core import Workspace, ScriptRunConfig, Environment, Experiment, Run\n",
    "from azureml.core import Datastore, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "print(f\"azureml version {aml.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twelvedata version 1.1.7\n"
     ]
    }
   ],
   "source": [
    "import twelvedata\n",
    "from twelvedata import TDClient\n",
    "\n",
    "print(f\"twelvedata version {twelvedata.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = Path(\".env\")\n",
    "assert env_path.exists()\n",
    "_ = load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure ML Workspace\n",
    "To setup an Azure ML Workspace you will need an azure account (with credit card). To spin it up simply go to https://portal.azure.com/ and type machine learning in the search bar and create a workspace.\n",
    "\n",
    "Once you have a workspace you will need to download the config.json prior to going to https://ml.azure.com/ to access your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_config_path = Path(\"config.json\")\n",
    "assert workspace_config_path.exists()\n",
    "ws = Workspace.from_config(path=workspace_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twelve Data Client\n",
    "I setup an account at https://twelvedata.com/ to get a free api key to try it out. I had not heard of it before, but it was the first thing that came up in my google search for free market data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.environ.get(\"apikey\")\n",
    "td = TDClient(apikey=apikey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Workspace Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating...\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-03-31T18:41:03.129000+00:00', 'errors': None, 'creationTime': '2021-03-31T18:41:00.552530+00:00', 'modifiedTime': '2021-03-31T18:41:16.029047+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "compute_name = \"aml-compute\"\n",
    "vm_size = \"Standard_NC6\"\n",
    "# vm_size = \"Standard_NC6s_v3\"\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found compute target: ' + compute_name)\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,  # STANDARD_NC6 is GPU-enabled\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=4)\n",
    "    # create the compute target\n",
    "    compute_target = ComputeTarget.create(\n",
    "        ws, compute_name, provisioning_config)\n",
    "\n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # For a more detailed view of current cluster status, use the 'status' property\n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Workspace Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TwelveData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List ETFs Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>currency</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8PSG</td>\n",
       "      <td>Invesco Physical Gold ETC</td>\n",
       "      <td>EUR</td>\n",
       "      <td>XETR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>BetaShares Australian High Interest Cash ETF</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ASX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>USD</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AADR</td>\n",
       "      <td>AdvisorShares Dorsey Wright ADR ETF</td>\n",
       "      <td>USD</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AASF</td>\n",
       "      <td>Airlie Australian Share Fund -- ETF Feeder</td>\n",
       "      <td>AUD</td>\n",
       "      <td>ASX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                                          name currency exchange\n",
       "0   8PSG                     Invesco Physical Gold ETC      EUR     XETR\n",
       "1    AAA  BetaShares Australian High Interest Cash ETF      AUD      ASX\n",
       "2   AAAU                  Perth Mint Physical Gold ETF      USD     NYSE\n",
       "3   AADR           AdvisorShares Dorsey Wright ADR ETF      USD     NYSE\n",
       "4   AASF    Airlie Australian Share Fund -- ETF Feeder      AUD      ASX"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etf_data = td.get_etf_list()\n",
    "etf_list = etf_data.as_json()\n",
    "etf_df = pd.DataFrame(etf_list)\n",
    "etf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ETF Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2020, 4, 13), datetime.date(2021, 3, 31))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_date = pd.Timestamp(dt.datetime.today())\n",
    "start_date = end_date - pd.tseries.offsets.BDay(252)\n",
    "\n",
    "start_date.to_pydatetime().date(), end_date.to_pydatetime().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>2.410000e+02</td>\n",
       "      <td>241.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>315.827105</td>\n",
       "      <td>318.008939</td>\n",
       "      <td>313.696467</td>\n",
       "      <td>316.061946</td>\n",
       "      <td>3.388346e+06</td>\n",
       "      <td>314.099308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.935291</td>\n",
       "      <td>30.777465</td>\n",
       "      <td>31.051232</td>\n",
       "      <td>30.962168</td>\n",
       "      <td>1.384690e+06</td>\n",
       "      <td>31.300765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>250.960010</td>\n",
       "      <td>255.490010</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.960010</td>\n",
       "      <td>7.530980e+05</td>\n",
       "      <td>247.567540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>294.420010</td>\n",
       "      <td>296.386990</td>\n",
       "      <td>293.149990</td>\n",
       "      <td>294.780000</td>\n",
       "      <td>2.359274e+06</td>\n",
       "      <td>289.318520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>314.355010</td>\n",
       "      <td>316.260010</td>\n",
       "      <td>312.989990</td>\n",
       "      <td>314.810000</td>\n",
       "      <td>3.065109e+06</td>\n",
       "      <td>313.609280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>342.239990</td>\n",
       "      <td>344.370000</td>\n",
       "      <td>340.179990</td>\n",
       "      <td>341.989990</td>\n",
       "      <td>4.069956e+06</td>\n",
       "      <td>340.674540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>365.079990</td>\n",
       "      <td>366.049990</td>\n",
       "      <td>363.250000</td>\n",
       "      <td>365.410000</td>\n",
       "      <td>8.397805e+06</td>\n",
       "      <td>362.513420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open        high         low       close        volume  \\\n",
       "count  241.000000  241.000000  241.000000  241.000000  2.410000e+02   \n",
       "mean   315.827105  318.008939  313.696467  316.061946  3.388346e+06   \n",
       "std     30.935291   30.777465   31.051232   30.962168  1.384690e+06   \n",
       "min    250.960010  255.490010  250.000000  250.960010  7.530980e+05   \n",
       "25%    294.420010  296.386990  293.149990  294.780000  2.359274e+06   \n",
       "50%    314.355010  316.260010  312.989990  314.810000  3.065109e+06   \n",
       "75%    342.239990  344.370000  340.179990  341.989990  4.069956e+06   \n",
       "max    365.079990  366.049990  363.250000  365.410000  8.397805e+06   \n",
       "\n",
       "              ema  \n",
       "count  241.000000  \n",
       "mean   314.099308  \n",
       "std     31.300765  \n",
       "min    247.567540  \n",
       "25%    289.318520  \n",
       "50%    313.609280  \n",
       "75%    340.674540  \n",
       "max    362.513420  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"VOO\"\n",
    "ts = td.time_series(\n",
    "    symbol=ticker, \n",
    "    interval=\"1day\",\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    outputsize=300\n",
    ")\n",
    "\n",
    "df = ts.with_ema().as_pandas()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>362.85999</td>\n",
       "      <td>365.82001</td>\n",
       "      <td>362.85999</td>\n",
       "      <td>365.41000</td>\n",
       "      <td>2687756</td>\n",
       "      <td>362.51342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>363.79001</td>\n",
       "      <td>363.79001</td>\n",
       "      <td>361.28500</td>\n",
       "      <td>363.00000</td>\n",
       "      <td>3637520</td>\n",
       "      <td>361.78927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>362.66000</td>\n",
       "      <td>364.67001</td>\n",
       "      <td>361.10971</td>\n",
       "      <td>363.79001</td>\n",
       "      <td>3062900</td>\n",
       "      <td>361.48659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>359.42999</td>\n",
       "      <td>364.35001</td>\n",
       "      <td>358.75000</td>\n",
       "      <td>363.95999</td>\n",
       "      <td>3212525</td>\n",
       "      <td>360.91074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>357.42001</td>\n",
       "      <td>360.23999</td>\n",
       "      <td>354.14001</td>\n",
       "      <td>359.47000</td>\n",
       "      <td>5361270</td>\n",
       "      <td>360.14842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime       open       high        low      close   volume        ema\n",
       "0 2021-03-31  362.85999  365.82001  362.85999  365.41000  2687756  362.51342\n",
       "1 2021-03-30  363.79001  363.79001  361.28500  363.00000  3637520  361.78927\n",
       "2 2021-03-29  362.66000  364.67001  361.10971  363.79001  3062900  361.48659\n",
       "3 2021-03-26  359.42999  364.35001  358.75000  363.95999  3212525  360.91074\n",
       "4 2021-03-25  357.42001  360.23999  354.14001  359.47000  5361270  360.14842"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure Workspace Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload ETF Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-26 04:00:00</td>\n",
       "      <td>359.42999</td>\n",
       "      <td>364.35001</td>\n",
       "      <td>358.75000</td>\n",
       "      <td>363.95999</td>\n",
       "      <td>3212525</td>\n",
       "      <td>360.91074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-25 04:00:00</td>\n",
       "      <td>357.42001</td>\n",
       "      <td>360.23999</td>\n",
       "      <td>354.14001</td>\n",
       "      <td>359.47000</td>\n",
       "      <td>5361270</td>\n",
       "      <td>360.14842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-24 04:00:00</td>\n",
       "      <td>360.70999</td>\n",
       "      <td>362.26999</td>\n",
       "      <td>357.44000</td>\n",
       "      <td>357.57999</td>\n",
       "      <td>3989728</td>\n",
       "      <td>360.31803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-23 04:00:00</td>\n",
       "      <td>359.79501</td>\n",
       "      <td>362.51001</td>\n",
       "      <td>359.79501</td>\n",
       "      <td>362.32001</td>\n",
       "      <td>1208455</td>\n",
       "      <td>361.00254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-22 04:00:00</td>\n",
       "      <td>359.88000</td>\n",
       "      <td>363.50000</td>\n",
       "      <td>359.76999</td>\n",
       "      <td>362.10999</td>\n",
       "      <td>3320390</td>\n",
       "      <td>360.67317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime       open       high        low      close   volume  \\\n",
       "0 2021-03-26 04:00:00  359.42999  364.35001  358.75000  363.95999  3212525   \n",
       "1 2021-03-25 04:00:00  357.42001  360.23999  354.14001  359.47000  5361270   \n",
       "2 2021-03-24 04:00:00  360.70999  362.26999  357.44000  357.57999  3989728   \n",
       "3 2021-03-23 04:00:00  359.79501  362.51001  359.79501  362.32001  1208455   \n",
       "4 2021-03-22 04:00:00  359.88000  363.50000  359.76999  362.10999  3320390   \n",
       "\n",
       "         ema  \n",
       "0  360.91074  \n",
       "1  360.14842  \n",
       "2  360.31803  \n",
       "3  361.00254  \n",
       "4  360.67317  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_or_upload_df(ws, data_store, df, ticker):\n",
    "    \n",
    "    dataset_name = f'{ticker.lower()}_ds'\n",
    "    try: \n",
    "        ds = Dataset.get_by_name(workspace=ws, name=dataset_name)\n",
    "        df = ds.to_pandas_dataframe()\n",
    "    except:\n",
    "        Dataset.Tabular.register_pandas_dataframe(df, data_store, dataset_name)\n",
    "        ds = Dataset.get_by_name(workspace=ws, name=dataset_name)\n",
    "        df = ds.to_pandas_dataframe()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "aml_df = get_or_upload_df(ws, data_store, df.reset_index(), ticker)\n",
    "aml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'aml-exp'\n",
    "aml_exp = Path(src_dir)\n",
    "if not aml_exp.exists(): aml_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aml-exp/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile aml-exp/train.py\n",
    "\n",
    "# Standard Libraries\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "# 3rd Party Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Model\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Classes \n",
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df,\n",
    "               label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "            # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "            # And cache it for next time\n",
    "            self._example = result\n",
    "        return result\n",
    "    \n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    def plot(self, plot_col, model=None, max_subplots=3):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        inputs, labels = self.example\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        \n",
    "        \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "          data=data,\n",
    "          targets=None,\n",
    "          sequence_length=self.total_window_size,\n",
    "          sequence_stride=1,\n",
    "          shuffle=True,\n",
    "          batch_size=32,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]\n",
    "    \n",
    "# Global Variables\n",
    "MAX_EPOCHS = 20\n",
    "CONV_WIDTH = 3\n",
    "\n",
    "# Read in Args\n",
    "parser = argparse.ArgumentParser(description='Train')\n",
    "parser.add_argument('--dataset_name', type=str, dest='dataset_name')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "# Paths\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "os.makedirs('./outputs/model', exist_ok=True)\n",
    "\n",
    "\n",
    "# ML Run\n",
    "run = Run.get_context()\n",
    "workspace = run.experiment.workspace\n",
    "\n",
    "\n",
    "# ML Dataset\n",
    "ds = Dataset.get_by_name(workspace=workspace, name=args.dataset_name)\n",
    "df = ds.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "# Date Feature Prep\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "date_time = pd.to_datetime(df.datetime)\n",
    "timestamp_s = date_time.map(dt.datetime.timestamp)\n",
    "\n",
    "df['day_sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['day_cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['year_sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['year_cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "\n",
    "\n",
    "# Data Filter\n",
    "features = ['day_sin', 'day_cos', 'ema']\n",
    "target = 'close'\n",
    "columns = features + [target]\n",
    "df = df[columns]\n",
    "\n",
    "# Data Splitting\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "\n",
    "# Data Normalization\n",
    "# TODO - normalize step based on train_df\n",
    "\n",
    "# Data Windows\n",
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=[target])\n",
    "wide_window = WindowGenerator(\n",
    "    input_width=24, label_width=24, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=[target])\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1, shift=1,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "    label_columns=[target])\n",
    "\n",
    "\n",
    "# Train Baseline\n",
    "baseline = Baseline(label_index=single_step_window.column_indices.get(target))\n",
    "baseline.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance, tst_performance = {}, {}\n",
    "val_performance['baseline'] = baseline.evaluate(single_step_window.val)\n",
    "tst_performance['baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\n",
    "\n",
    "wide_window.plot(target, baseline)\n",
    "run.log_image('baseline_pred', plot=plt)\n",
    "\n",
    "# Train Models\n",
    "def compile_and_fit(model, window, patience=4):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "    return history\n",
    "\n",
    "# Train Linear Model\n",
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "history = compile_and_fit(linear, single_step_window)\n",
    "\n",
    "val_performance['linear'] = linear.evaluate(single_step_window.val)\n",
    "tst_performance['linear'] = linear.evaluate(single_step_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(linear, './outputs/model/linear')\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax = fig1.add_subplot(111)\n",
    "ax.bar(x = range(len(train_df.columns)),\n",
    "        height=linear.layers[0].kernel[:,0].numpy())\n",
    "ax.set_xticks(range(len(train_df.columns)))\n",
    "_ = ax.set_xticklabels(train_df.columns, rotation=90)\n",
    "run.log_image('linear_coef', plot=plt)\n",
    "\n",
    "wide_window.plot(target, linear)\n",
    "run.log_image('linear_pred', plot=plt)\n",
    "\n",
    "# Train Single Step Dense Model\n",
    "single_step_dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "history = compile_and_fit(single_step_dense, single_step_window)\n",
    "\n",
    "val_performance['single_step_dense'] = single_step_dense.evaluate(single_step_window.val)\n",
    "tst_performance['single_step_dense'] = single_step_dense.evaluate(single_step_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(single_step_dense, './outputs/model/single_step_dense')\n",
    "\n",
    "wide_window.plot(target, single_step_dense)\n",
    "run.log_image('single_step_dense_pred', plot=plt)\n",
    "\n",
    "# Train Multi Step Dense Model\n",
    "multi_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])\n",
    "history = compile_and_fit(multi_step_dense, conv_window)\n",
    "\n",
    "val_performance['multi_step_dense'] = multi_step_dense.evaluate(conv_window.val)\n",
    "tst_performance['multi_step_dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(multi_step_dense, './outputs/model/multi_step_dense')\n",
    "\n",
    "# wide_window.plot(target, multi_step_dense)\n",
    "# run.log_image('multi_step_dense_pred', plot=plt)\n",
    "\n",
    "# Train Conv Model\n",
    "conv = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])\n",
    "history = compile_and_fit(conv, conv_window)\n",
    "\n",
    "val_performance['conv'] = conv.evaluate(conv_window.val)\n",
    "tst_performance['conv'] = conv.evaluate(conv_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(conv, './outputs/model/conv')\n",
    "\n",
    "# Train LSTM Model\n",
    "lstm = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(10, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "history = compile_and_fit(lstm, wide_window)\n",
    "\n",
    "val_performance['lstm'] = lstm.evaluate(wide_window.val)\n",
    "tst_performance['lstm'] = lstm.evaluate(wide_window.test, verbose=0)\n",
    "\n",
    "tf.saved_model.save(lstm, './outputs/model/lstm')\n",
    "\n",
    "# Performance\n",
    "x = np.arange(len(val_performance))\n",
    "width = 0.3\n",
    "\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = lstm.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in tst_performance.values()]\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(111)\n",
    "b1 = ax.bar(x - 0.2, val_mae, width, label='validation')\n",
    "# b2 = ax.bar(x + 0.2, test_mae, width, label='test')\n",
    "ax.set_xticks(range(len(val_mae)))\n",
    "_ = ax.set_xticklabels(val_performance.keys(), rotation=90)\n",
    "run.log_image('performance_mae', plot=plt)\n",
    "\n",
    "\n",
    "# Log Results & Select Best Model\n",
    "best_model, best_score = None, None\n",
    "if run is not None:\n",
    "    \n",
    "    for k, v in val_performance.items():\n",
    "        run.log_list(f'val_{k}', v)\n",
    "        \n",
    "    for k, v in tst_performance.items():\n",
    "        run.log_list(f'tst_{k}', v)\n",
    "        try:\n",
    "            mae = float(v[1])    \n",
    "            if best_score is None and best_model is None: \n",
    "                best_model = k\n",
    "                best_score = mae\n",
    "            elif best_score > mae:\n",
    "                best_model = k\n",
    "                best_score = mae   \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    run.log('best_model', best_model)\n",
    "    run.log('best_score', best_score)\n",
    "\n",
    "if best_model != \"baseline\": model = run.register_model(model_name=best_model, model_path=f'outputs/model/{best_model}')\n",
    "\n",
    "#### Setup Training Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_run_config = RunConfiguration()\n",
    "aml_run_config.target = compute_target\n",
    "\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Add some packages relied on by data prep step\n",
    "deps = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn', 'matplotlib'], \n",
    "    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]', 'azureml-pipeline', 'azureml-interpret'], \n",
    "    python_version='3.6.2',\n",
    "    pin_sdk_version=True)\n",
    "deps.add_tensorflow_pip_package(core_type='gpu', version='2.3.1')\n",
    "aml_run_config.environment.python.conda_dependencies = deps\n",
    "\n",
    "\n",
    "src = ScriptRunConfig(source_directory=src_dir,\n",
    "                      script='train.py',\n",
    "                      arguments=['--dataset_name', f'{ticker.lower()}_ds'],\n",
    "                      run_config=aml_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "experiment = Experiment(ws, 'aml_exp')\n",
    "script_run = experiment.submit(src)\n",
    "script_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bb073aa2d443c8a729b6e6b0bbc344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/aml_exp_1617233359_a7595e84?wsid=/subscriptions/f3b5840b-706e-44ba-8aa1-6fd3fc8aaab0/resourcegroups/ds-workspace/workspaces/minion-lab&tid=e6777dcd-6f87-4dd0-92e5-e98312157dac\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"run_properties\": {\"run_id\": \"aml_exp_1617233359_a7595e84\", \"created_utc\": \"2021-03-31T23:29:21.673551Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"c9211419-0d01-434d-b306-8b3a4c68aeee\", \"azureml.git.repository_uri\": \"https://github.com/kslader8/kslader8-thoughts.git\", \"mlflow.source.git.repoURL\": \"https://github.com/kslader8/kslader8-thoughts.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"7952e728b81a7a29ee107e7a37c7b8a7dd64200d\", \"mlflow.source.git.commit\": \"7952e728b81a7a29ee107e7a37c7b8a7dd64200d\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-03-31T23:35:31.60674Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/azureml-logs/55_azureml-execution-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt?sv=2019-02-02&sr=b&sig=mywCDRW5f1NYwbMf0BLVdGPqlDtJk29FkssEA7DJg0Q%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/azureml-logs/65_job_prep-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt?sv=2019-02-02&sr=b&sig=sgf6O2SkD9bIK9RtyWFaMa2x84fWUjyvmb7zwYSc78I%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=dF2vN1cKQsOvBrshACRBOcYIxWeY4TWU576c2Xz4eeY%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"azureml-logs/75_job_post-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/azureml-logs/75_job_post-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt?sv=2019-02-02&sr=b&sig=b30%2BTzsthnoeDaNjKo9af%2FGoI8kgOWEmgej%2FdAOWnYA%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"azureml-logs/process_info.json\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=l7xDeKuJ6QGqsugY9a2PZFlXrU4sF05E%2FKHrTOV4UNM%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"azureml-logs/process_status.json\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=SxwEkEQkZQ7yvD3H1DWZ0D7SQAnNLXGlGiH9wpZ99Tw%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"logs/azureml/106_azureml.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/logs/azureml/106_azureml.log?sv=2019-02-02&sr=b&sig=ZLF6ecq82Pj8pCPRMtBlfFnueigr%2F0ao5eQzdjI%2BCVc%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=m%2FlJ%2F8woZKyRgQ%2B9fE16E5KMLpGC9%2BOIm1tSYLeOZa4%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=XT9Cyp%2BPHKt%2FNIKqm%2FLgAWfsImcWHMM8K936r3%2F9KNc%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=WBVwY2GOElMvWXzU3MIUoaiom9tU8E2KnxuLb1nRcWs%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://minionlab0571264079.blob.core.windows.net/azureml/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=wVkgJ%2FCGU3VjR2pRJeSLrLCYY4bOP0R0k2BIGPIegss%3D&st=2021-03-31T23%3A25%3A25Z&se=2021-04-01T07%3A35%3A25Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt\"], [\"logs/azureml/106_azureml.log\"]], \"run_duration\": \"0:06:09\", \"run_number\": \"27\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"baseline_pred\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/baseline_pred_1617233672.png\"]}]}, {\"name\": \"linear_coef\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/linear_coef_1617233676.png\"]}]}, {\"name\": \"linear_pred\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/linear_pred_1617233676.png\"]}]}, {\"name\": \"single_step_dense_pred\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/single_step_dense_pred_1617233681.png\"]}]}, {\"name\": \"performance_mae\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/performance_mae_1617233696.png\"]}]}, {\"name\": \"val_baseline\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [18.686260223388672, 3.2065956592559814]}]}, {\"name\": \"val_linear\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [605690.9375, 777.9266357421875]}]}, {\"name\": \"val_single_step_dense\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [12.129790306091309, 2.596614122390747]}]}, {\"name\": \"val_multi_step_dense\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [23.9085693359375, 3.903738021850586]}]}, {\"name\": \"val_conv\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [17.16225242614746, 2.9845776557922363]}]}, {\"name\": \"val_lstm\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [81859.9296875, 286.0354919433594]}]}, {\"name\": \"tst_baseline\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [20.958070755004883, 3.920870542526245]}]}, {\"name\": \"tst_linear\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [502930.53125, 709.0858154296875]}]}, {\"name\": \"tst_single_step_dense\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [14.61068344116211, 3.2360215187072754]}]}, {\"name\": \"tst_multi_step_dense\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [20.170698165893555, 4.205769062042236]}]}, {\"name\": \"tst_conv\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0, 1], \"series\": [{\"data\": [17.6562557220459, 3.5512776374816895]}]}, {\"name\": \"best_model\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0], \"series\": [{\"data\": [\"single_step_dense\"]}]}, {\"name\": \"best_score\", \"run_id\": \"aml_exp_1617233359_a7595e84\", \"categories\": [0], \"series\": [{\"data\": [3.2360215187072754]}]}], \"run_logs\": \"2021-03-31 23:34:19,272|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-03-31 23:34:19,272|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-03-31 23:34:19,302|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-03-31 23:34:19,302|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-03-31 23:34:19,695|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2021-03-31 23:34:19,695|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2021-03-31 23:34:19,695|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2021-03-31 23:34:19,695|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2021-03-31 23:34:19,695|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7fd2d5ea57b8> for run source hyperdrive\\n2021-03-31 23:34:19,711|azureml.core|WARNING|Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-dataprep 2.13.2 (/azureml-envs/azureml_7c53d162ce55be5bb112991a6f053fb8/lib/python3.6/site-packages), Requirement.parse('azureml-dataprep<2.12.0a,>=2.11.0a'), {'azureml-dataset-runtime'}).\\n2021-03-31 23:34:19,757|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7fd2d5d13f28> for run source azureml.PipelineRun\\n2021-03-31 23:34:19,767|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7fd2d5d1b9d8> for run source azureml.ReusedStepRun\\n2021-03-31 23:34:19,777|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7fd2d5d1b950> for run source azureml.StepRun\\n2021-03-31 23:34:19,786|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fd2d601b1e0> for run source azureml.scriptrun\\n2021-03-31 23:34:19,787|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 23:34:19,787|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 23:34:19,789|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 23:34:19,797|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-03-31 23:34:19,797|azureml.core.authentication|DEBUG|Time to expire 1814101.202649 seconds\\n2021-03-31 23:34:19,797|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-03-31 23:34:19,797|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-03-31 23:34:19,851|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:19,852|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:19,852|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:19,852|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:19,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:19,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:19,853|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:19,887|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 23:34:19,887|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 23:34:19,949|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:19,949|azureml._SubmittedRun#aml_exp_1617233359_a7595e84|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'c9211419-0d01-434d-b306-8b3a4c68aeee', 'azureml.git.repository_uri': 'https://github.com/kslader8/kslader8-thoughts.git', 'mlflow.source.git.repoURL': 'https://github.com/kslader8/kslader8-thoughts.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '7952e728b81a7a29ee107e7a37c7b8a7dd64200d', 'mlflow.source.git.commit': '7952e728b81a7a29ee107e7a37c7b8a7dd64200d', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-31 23:34:19,949|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-31 23:34:19,950|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-03-31 23:34:19,950|azureml.WorkerPool|DEBUG|[START]\\n2021-03-31 23:34:19,950|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-03-31 23:34:19,950|azureml.RunStatusContext|DEBUG|[START]\\n2021-03-31 23:34:19,950|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-03-31 23:34:19,950|azureml.MetricsClient|DEBUG|[START]\\n2021-03-31 23:34:19,950|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-03-31 23:34:19,950|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-03-31 23:34:19,951|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-03-31 23:34:19,951|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617233359_a7595e84/mounts/workspaceblobstore/azureml/aml_exp_1617233359_a7595e84\\n2021-03-31 23:34:19,951|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-31 23:34:19,951|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617233359_a7595e84/mounts/workspaceblobstore/azureml/aml_exp_1617233359_a7595e84\\n2021-03-31 23:34:22,509|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 23:34:22,509|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 23:34:22,509|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 23:34:22,510|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,512|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,514|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,514|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,520|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,520|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,520|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,559|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 23:34:22,559|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 23:34:22,628|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:22,629|azureml._SubmittedRun#aml_exp_1617233359_a7595e84|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'c9211419-0d01-434d-b306-8b3a4c68aeee', 'azureml.git.repository_uri': 'https://github.com/kslader8/kslader8-thoughts.git', 'mlflow.source.git.repoURL': 'https://github.com/kslader8/kslader8-thoughts.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '7952e728b81a7a29ee107e7a37c7b8a7dd64200d', 'mlflow.source.git.commit': '7952e728b81a7a29ee107e7a37c7b8a7dd64200d', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-31 23:34:22,629|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-31 23:34:22,851|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 23:34:22,851|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 23:34:22,852|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 23:34:22,852|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,855|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,856|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,856|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,857|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,857|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:22,857|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:23,464|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 23:34:23,464|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 23:34:23,464|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 23:34:23,464|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:23,465|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:23,465|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:23,465|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:23,466|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:23,466|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:23,466|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,540|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-03-31 23:34:29,540|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-03-31 23:34:29,540|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-31 23:34:29,541|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,541|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,542|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2021-03-31 23:34:29,550|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 23:34:29,550|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 23:34:29,654|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:33,078|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-03-31 23:34:33,079|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-03-31 23:34:33,079|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-31 23:34:33,079|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-31 23:34:33,235|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:33,236|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-31 23:34:33,298|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.aml_exp_1617233359_a7595e84/baseline_pred_1617233672.png with size 103075, file size 103075.\\n2021-03-31 23:34:33,298|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 23:34:33,299|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 23:34:33,299|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 23:34:34,299|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-31 23:34:34,299|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-31 23:34:34,300|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-03-31 23:34:34,300|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:34,300|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-31 23:34:34,300|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-31 23:34:34,300|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-03-31 23:34:34,300|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:34,301|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-31 23:34:34,301|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-31 23:34:34,301|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-03-31 23:34:34,301|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-31 23:34:34,301|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-31 23:34:34,301|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-31 23:34:34,303|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-31 23:34:34,305|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-31 23:34:34,306|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-31 23:34:34,307|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:34:34,307|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-03-31 23:34:34,307|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-31 23:34:34,456|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:36,574|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-03-31 23:34:36,574|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-03-31 23:34:36,575|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-31 23:34:36,575|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-31 23:34:36,719|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:36,719|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-31 23:34:36,780|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.aml_exp_1617233359_a7595e84/linear_coef_1617233676.png with size 11980, file size 11980.\\n2021-03-31 23:34:37,172|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-03-31 23:34:37,172|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-03-31 23:34:37,172|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-31 23:34:37,172|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-31 23:34:37,300|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-31 23:34:37,300|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-31 23:34:37,300|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-03-31 23:34:37,301|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:37,301|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-31 23:34:37,301|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-31 23:34:37,301|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-03-31 23:34:37,301|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-31 23:34:37,301|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:37,302|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-31 23:34:37,302|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-31 23:34:37,302|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 1__log_batch_v2 to queue of approximate size: 1\\n2021-03-31 23:34:37,302|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-31 23:34:37,302|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-31 23:34:37,306|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-31 23:34:37,306|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-31 23:34:37,306|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-31 23:34:37,306|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:34:37,306|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-03-31 23:34:37,307|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-31 23:34:37,338|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:37,339|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-31 23:34:37,423|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.aml_exp_1617233359_a7595e84/linear_pred_1617233676.png with size 50362, file size 50362.\\n2021-03-31 23:34:37,445|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:38,301|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-31 23:34:38,301|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-31 23:34:38,302|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-03-31 23:34:38,303|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-31 23:34:38,303|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:38,303|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-03-31 23:34:38,304|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.2__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:38,304|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-31 23:34:38,304|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-31 23:34:38,304|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 2__log_batch_v2 to queue of approximate size: 2\\n2021-03-31 23:34:38,305|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-31 23:34:38,305|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-31 23:34:38,307|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-31 23:34:38,312|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-31 23:34:38,312|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-31 23:34:38,313|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-31 23:34:38,313|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-31 23:34:38,313|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:34:38,314|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-03-31 23:34:38,314|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-31 23:34:38,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:41,680|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-03-31 23:34:41,680|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-03-31 23:34:41,681|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-31 23:34:41,681|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-31 23:34:41,839|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:41,840|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-31 23:34:41,872|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.aml_exp_1617233359_a7595e84/single_step_dense_pred_1617233681.png with size 100873, file size 100873.\\n2021-03-31 23:34:42,304|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-31 23:34:42,304|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-31 23:34:42,304|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-03-31 23:34:42,304|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:42,304|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-31 23:34:42,304|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-31 23:34:42,305|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-03-31 23:34:42,305|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-31 23:34:42,305|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.3__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:42,305|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-31 23:34:42,305|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-31 23:34:42,305|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 3__log_batch_v2 to queue of approximate size: 3\\n2021-03-31 23:34:42,306|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-31 23:34:42,306|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-31 23:34:42,309|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-31 23:34:42,310|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-31 23:34:42,310|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-31 23:34:42,310|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:34:42,310|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-03-31 23:34:42,311|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-31 23:34:42,444|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:49,790|azureml.core.authentication|DEBUG|Time to expire 1814071.209654 seconds\\n2021-03-31 23:34:57,071|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-03-31 23:34:57,071|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-03-31 23:34:57,072|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-03-31 23:34:57,072|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-03-31 23:34:57,226|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:57,227|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-03-31 23:34:57,258|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.aml_exp_1617233359_a7595e84/performance_mae_1617233696.png with size 14123, file size 14123.\\n2021-03-31 23:34:57,259|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.aml_exp_1617233359_a7595e84, outputs/model/single_step_dense\\n2021-03-31 23:34:57,259|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2021-03-31 23:34:57,259|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2021-03-31 23:34:57,260|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2021-03-31 23:34:57,260|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:57,263|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2021-03-31 23:34:57,263|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2021-03-31 23:34:57,263|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2021-03-31 23:34:57,370|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:34:57,370|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2021-03-31 23:34:57,370|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[START]\\n2021-03-31 23:34:57,370|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.AssetsClient|DEBUG|ClientBase: Calling create with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/assets\\n2021-03-31 23:34:57,390|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-03-31 23:34:57,390|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-03-31 23:34:57,391|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 15.\\n2021-03-31 23:34:57,391|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:57,391|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-03-31 23:34:57,391|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-03-31 23:34:57,392|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 15 values.\\n2021-03-31 23:34:57,392|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-03-31 23:34:57,392|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.4__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-03-31 23:34:57,392|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-03-31 23:34:57,392|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-03-31 23:34:57,392|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 4__log_batch_v2 to queue of approximate size: 4\\n2021-03-31 23:34:57,392|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-03-31 23:34:57,392|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-03-31 23:34:57,400|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-03-31 23:34:57,400|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-03-31 23:34:57,400|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-03-31 23:34:57,400|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:34:57,400|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-03-31 23:34:57,400|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-03-31 23:34:57,506|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:57,512|azureml.ModelsClient.register-async:False|DEBUG|[START]\\n2021-03-31 23:34:57,513|azureml.ModelsClient|DEBUG|ClientBase: Calling register with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models\\n2021-03-31 23:34:58,005|azureml.ModelsClient.register-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:58,007|azureml.WorkspaceClient.get-async:False|DEBUG|[START]\\n2021-03-31 23:34:58,007|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}\\n2021-03-31 23:34:58,074|azureml.WorkspaceClient.get-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:58,074|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-31 23:34:58,074|azureml.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-31 23:34:58,128|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|WARNING|Metrics Client: Failed to post metric with name tst_lstm due to the following error \\\"Metric column found with a malformed type\\nMetric column found with a malformed type\\\"\\n2021-03-31 23:34:58,128|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:58,133|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-31 23:34:58,133|azureml.core.run|DEBUG|Available factories for run types {'hyperdrive': <function HyperDriveRun._from_run_dto at 0x7fd2d5ea57b8>, 'azureml.PipelineRun': <function PipelineRun._from_dto at 0x7fd2d5d13f28>, 'azureml.ReusedStepRun': <function StepRun._from_reused_dto at 0x7fd2d5d1b9d8>, 'azureml.StepRun': <function StepRun._from_dto at 0x7fd2d5d1b950>, 'azureml.scriptrun': <function ScriptRun._from_run_dto at 0x7fd2d601b1e0>}\\n2021-03-31 23:34:58,133|azureml.core.run|DEBUG|Initializing Run aml_exp_1617233359_a7595e84 from type azureml.scriptrun\\n2021-03-31 23:34:58,136|azureml.ScriptRun#aml_exp_1617233359_a7595e84|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'c9211419-0d01-434d-b306-8b3a4c68aeee', 'azureml.git.repository_uri': 'https://github.com/kslader8/kslader8-thoughts.git', 'mlflow.source.git.repoURL': 'https://github.com/kslader8/kslader8-thoughts.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '7952e728b81a7a29ee107e7a37c7b8a7dd64200d', 'mlflow.source.git.commit': '7952e728b81a7a29ee107e7a37c7b8a7dd64200d', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-31 23:34:58,136|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-31 23:34:58,200|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-31 23:34:58,200|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617233359_a7595e84/mounts/workspaceblobstore/azureml/aml_exp_1617233359_a7595e84\\n2021-03-31 23:34:58,200|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617233359_a7595e84/mounts/workspaceblobstore/azureml/aml_exp_1617233359_a7595e84 to /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617233359_a7595e84/mounts/workspaceblobstore/azureml/aml_exp_1617233359_a7595e84\\n2021-03-31 23:34:58,200|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/minion-lab/azureml/aml_exp_1617233359_a7595e84/mounts/workspaceblobstore/azureml/aml_exp_1617233359_a7595e84\\n2021-03-31 23:34:58,201|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-03-31 23:34:58,201|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-03-31 23:34:58,201|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 23:34:58,201|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 23:34:58,201|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 23:34:58,201|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 23:34:58,201|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:34:58,201|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:34:58,201|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:34:58,202|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 23:34:58,203|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 23:34:58,203|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 23:34:58,265|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 23:35:03,271|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-03-31 23:35:08,356|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-03-31 23:35:08,417|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,417|azureml.MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,417|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,417|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,417|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,417|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-03-31 23:35:08,417|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 23:35:08,417|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 23:35:08,418|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 23:35:08,487|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 23:35:08,487|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 23:35:08,488|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,489|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,489|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 23:35:08,489|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,567|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2), AsyncTask(1__log_batch_v2), AsyncTask(2__log_batch_v2), AsyncTask(3__log_batch_v2), AsyncTask(4__log_batch_v2)].\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.2__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-31 23:35:08,568|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.2__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.2__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.3__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.3__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.3__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.4__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.4__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.4__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 23:35:08,569|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 23:35:08,650|azureml._SubmittedRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 23:35:08,650|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,650|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-31 23:35:08,651|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-31 23:35:08,652|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-31 23:35:08,710|azureml.ScriptRun#aml_exp_1617233359_a7595e84.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-31 23:35:08,710|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-03-31 23:35:08,710|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-03-31 23:35:08,710|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-03-31 23:35:08,710|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.25.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(script_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it best to simply go to the experiment portal url to review from the gui. It contains all the runs from your experiment and makes it easy to review changes from a central location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/aml_exp_1617233359_a7595e84?wsid=/subscriptions/f3b5840b-706e-44ba-8aa1-6fd3fc8aaab0/resourcegroups/ds-workspace/workspaces/minion-lab&tid=e6777dcd-6f87-4dd0-92e5-e98312157dac'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_run.get_portal_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can choose to do the model review inside the notebook too. \n",
    "\n",
    "The first place to look when doing this is the experiments metrics. In this example I'm logging the mse and mae for validation & test datasets for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_pred': 'aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/baseline_pred_1617233672.png',\n",
       " 'linear_coef': 'aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/linear_coef_1617233676.png',\n",
       " 'linear_pred': 'aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/linear_pred_1617233676.png',\n",
       " 'single_step_dense_pred': 'aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/single_step_dense_pred_1617233681.png',\n",
       " 'performance_mae': 'aml://artifactId/ExperimentRun/dcid.aml_exp_1617233359_a7595e84/performance_mae_1617233696.png',\n",
       " 'val_baseline': [18.686260223388672, 3.2065956592559814],\n",
       " 'val_linear': [605690.9375, 777.9266357421875],\n",
       " 'val_single_step_dense': [12.129790306091309, 2.596614122390747],\n",
       " 'val_multi_step_dense': [23.9085693359375, 3.903738021850586],\n",
       " 'val_conv': [17.16225242614746, 2.9845776557922363],\n",
       " 'val_lstm': [81859.9296875, 286.0354919433594],\n",
       " 'tst_baseline': [20.958070755004883, 3.920870542526245],\n",
       " 'tst_linear': [502930.53125, 709.0858154296875],\n",
       " 'tst_single_step_dense': [14.61068344116211, 3.2360215187072754],\n",
       " 'tst_multi_step_dense': [20.170698165893555, 4.205769062042236],\n",
       " 'tst_conv': [17.6562557220459, 3.5512776374816895],\n",
       " 'best_model': 'single_step_dense',\n",
       " 'best_score': 3.2360215187072754}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = script_run.get_metrics()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_val             : 3.2066\n",
      "baseline_tst             : 3.9209\n",
      "conv_val                 : 2.9846\n",
      "conv_tst                 : 3.5513\n",
      "linear_val               : 777.9266\n",
      "linear_tst               : 709.0858\n",
      "lstm_val                 : 286.0355\n",
      "multi_step_dense_val     : 3.9037\n",
      "multi_step_dense_tst     : 4.2058\n",
      "single_step_dense_val    : 2.5966\n",
      "single_step_dense_tst    : 3.2360\n"
     ]
    }
   ],
   "source": [
    "mae_metrics = []\n",
    "for name, value in metrics.items():\n",
    "    if isinstance(value, list) and len(value) >= 2:\n",
    "        splits = name.split(\"_\")\n",
    "        grp, model = splits[0], \"_\".join(splits[1:])\n",
    "        mae_metrics.append((model, grp, value[1]))\n",
    "        \n",
    "for model, grp, mae in sorted(mae_metrics, key=lambda o: o[0]):\n",
    "    name = f'{model}_{grp}'\n",
    "    print(f'{name:25s}: {mae:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be useful to review the log files to figure out wtf is going wrong constantly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/55_azureml-execution-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt',\n",
       " 'azureml-logs/70_driver_log.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_0c357d5ce4f8eda465b3f47f7b95b579e656516823eef14997ff742d99f7565e_d.txt',\n",
       " 'azureml-logs/process_info.json',\n",
       " 'azureml-logs/process_status.json',\n",
       " 'baseline_pred_1617233672.png',\n",
       " 'linear_coef_1617233676.png',\n",
       " 'linear_pred_1617233676.png',\n",
       " 'logs/azureml/106_azureml.log',\n",
       " 'logs/azureml/dataprep/backgroundProcess.log',\n",
       " 'logs/azureml/dataprep/backgroundProcess_Telemetry.log',\n",
       " 'logs/azureml/job_prep_azureml.log',\n",
       " 'logs/azureml/job_release_azureml.log',\n",
       " 'outputs/model/conv/saved_model.pb',\n",
       " 'outputs/model/conv/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/conv/variables/variables.index',\n",
       " 'outputs/model/linear/saved_model.pb',\n",
       " 'outputs/model/linear/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/linear/variables/variables.index',\n",
       " 'outputs/model/lstm/saved_model.pb',\n",
       " 'outputs/model/lstm/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/lstm/variables/variables.index',\n",
       " 'outputs/model/multi_step_dense/saved_model.pb',\n",
       " 'outputs/model/multi_step_dense/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/multi_step_dense/variables/variables.index',\n",
       " 'outputs/model/single_step_dense/saved_model.pb',\n",
       " 'outputs/model/single_step_dense/variables/variables.data-00000-of-00001',\n",
       " 'outputs/model/single_step_dense/variables/variables.index',\n",
       " 'performance_mae_1617233696.png',\n",
       " 'single_step_dense_pred_1617233681.png']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = script_run.get_file_names()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "This is an important step if you don't want to end up having a big bill at the end of the month 😉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting compute cleanup\n",
      "deleting aml-compute instance\n",
      "deleting ks-nb instance\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "compute cleanup complete\n"
     ]
    }
   ],
   "source": [
    "print(\"starting compute cleanup\")\n",
    "\n",
    "for name, compute in ws.compute_targets.items():\n",
    "    print(f\"deleting {name} instance\")\n",
    "    compute.delete()\n",
    "    \n",
    "while len(ws.compute_targets.items()) != 0:\n",
    "    continue\n",
    "\n",
    "print(\"compute cleanup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
